...
Welcome back to 600.2x.
In the introduction to the course,
I talked about computational models.
And I said we're going to look at three kinds of models--
optimization models, statistical models, and simulation models.
In the next two lectures, we'll be
focusing on the role of the mature field of optimization
models.
So what is an optimization model?
The notion of an optimization problem
provides a structured way to think about solving
lots of computational problems.
Whenever you set about solving a problem that
involves finding the biggest, the smallest, the most,
the fewest, the fastest, the least expensive, et cetera,
there's a good chance that you can map that problem
onto a classic optimization problem for which there is
a known computational solution.
So what is a classic optimization problem look like?
It's got two parts.
The first part is an objective function
that is to be maximized or minimized.
For example, we want to minimize the time spent traveling
from New York to Boston.
The second part of an optimization model
is a set of constraints, possibly empty,
that must be honored.
For example, I want to get from New York to Boston,
but I can't spend more than $100,
or I've got to be in Boston by 5 PM.
To give you a sense of how ubiquitous optimization
problems are, all of the logos in the lower right-hand corner
of this slide belong to just travel-related companies,
one small segment of industry that
solve optimization problems as a central part of their business.

What do I want you to take away from this lecture
and the next lecture?
One, many problems of real importance
can be simply formulated in a way that leads naturally
to a computational solution.
Two, it's way easier to reduce a problem
to a problem that's already been solved than it is to invent
your own solution to a problem.
So this idea of taking an informal problem,
formalizing it in a way that says, oh, that's
been solved already.
I can just use that-- as a message
I want you to take away.
I want you to take away the fact that optimization problems are
hard.
I don't mean hard in the sense that we scratch our head
and don't know how to solve them.
I mean hard in a computational complexity sense--
that they can run for a really long time.
Because of that, we often don't actually solve them.
We approximate them and we use a greedy algorithm
to find not an optimal solution, but a solution that
is good enough.
Let's start with the famous problem
called the knapsack problem.
For those of you who don't know what a knapsack is,
it's a backpack.
Here's a picture of a very old one.
The basic idea behind the knapsack problem
is a simple one.
You've got a knapsack with finite capacity and more
objects you'd like to put in than will actually fit in,
and you're deciding which objects to take,
which objects to leave behind.
Essentially, you have limited strength.
There's a maximum weight you can carry.
How do you decide which stuff to take
and which stuff to leave behind?
Now, of course, the knapsack doesn't
have to be a physical one.
Imagine that you are an overweight college
professor who has just decided to go
on a 1,500 calorie-a-day diet.
That imaginary person needs to optimize an objective function
related to his taste buds, the most possible pleasure
you can get by eating while satisfying the 1,500
calorie a day constraint.

Very good.
Now I should mention that there were
two variants of the knapsack problem-- 0-1 knapsack
problem-- it's called that because you either
take the whole object, one, or not at all.
So if you are, say, stealing a Picasso painting,
there isn't much point in stealing half the painting.
Either take the whole thing or you take none of it.
There's also the continuous or fractional knapsack problem.
I don't actually have to eat this whole plate of spaghetti.
I can take only part of it.
The 0-1 problem is considerably harder than the continuous one.
You can think of the analogy of gold.
If I have my knapsack and I'm trying
to decide how much gold to take, deciding
how many bars I can fit in can be hard,
but if it's just gold dust, I just fill it up
until I can't carry it anymore, and I always
get to my maximum weight.
Whereas with the bar, maybe I could carry a half a bar more,
but there's no way to split it.
OK, that's an informal look.
Let's now look at how can we formalize a 0-1 knapsack
problem.
So we'll start by representing each item
by a pair of the value of the item
and the weight of the item.

We'll then say the knapsack can accommodate items
with a total weight of no more than w.
Now, of course, weight doesn't have
to be literally pounds or kilos.
Weight could be calories.
Weight could be credits for a course.
Weight could be miles if you're driving.
Weight could be time-- anything that you are worried about.
We'll then have a vector-- call it L-- of length n,
representing the set of available items to take.
So think of each element of the vector
as representing a single item.
And then we'll have a vector v of length n also,
indicating whether or not each item is taken.
If we decide to put an item in the knapsack,
the vector will have a value of 1 in the spot corresponding
to that item.
If we decide not to take the item,
the vector will have a 0 in that spot.

Given that setup, we can then very simply formalize
the problem as follows.
Find a v that maximizes this term.

What is this term saying?
It says for each item, i, we'll look at that spot in the vector
and we'll multiply the value in the vector
by the value of that item.
Notice that if we don't take the item, v sub i will be 0,
and so we don't care what the value is.
So essentially, this is summing up
the value of all of the items we decide to take.
We then need to obey the constraint here
that for all the items we take, the weights sum up
to less than w.
So it's a very simple formulation of the problem.
In any 0-1 knapsack problem, we'll
have a formulation that looks a lot like this.
Of course, the objective function here
can be more complicated and you can
have no constraint sometimes, or well more than one constraint.
How can we solve these problems?
Well, it's a really simple way to solve it.
We can enumerate all possible combinations of items.
That is, to say generate every subset of items
that we could choose to take, including
the empty subset in the subset with all of the items.
That's called the power set.
We can then remove all of the combination whose
total units exceed the allowed weight because we're not
allowed to take those.
We're obeying here a constraint.
And then from the remaining combinations,
choose any one whose value is the largest.
I say anyone because there might be
and there often is more than one optimal solution.

This is great, but it's usually not a practical way
to solve a knapsack problem.
Why not?
Well, how big is the power set?
Well, recall that we used a vector v of length n
to indicate whether or not the items were taken.
So the set of possible vectors represents the set
of possible choices of items.
The vector that's all 0 says we didn't take any.
The vector that's all 1 says we took them all.
And then every other possibility is represented
by some sequence of 0s and 1s.
Well, how many different numbers can we were present in n bits
or we can represent 2 to the n numbers?
So right away, we know the power set is really big.
It's of size 2 to the n.
Well, that means that the algorithm is exponential.

If the algorithm is exponential, it can take a very long time
to solve.
For example, if there were a hundreds items to choose from--
and I do sometimes go to restaurants
with 100 items on the menu-- the power set is of this size--
considerably larger than I would like to actually consider.
What are we going to do about that?
Are we just being stupid is the first question.
I gave you a very straightforward,
obviously correct algorithm, and maybe I just-- there's
a really good algorithm that I just didn't show you.
Well, no.
The 0-1 knapsack problem is inherently exponential.
That means that you cannot-- there does not exist
an algorithm that solves it in less than exponential time.
But don't despair.
It's a hard problem, but that doesn't mean
we can't solve it in practice.
As we will see in the next segment and in lecture two,
there are good ways to find approximate solutions
to knapsack problems and there are even
good ways to find truly optimal solutions to knapsack problems
that work almost all the time.
