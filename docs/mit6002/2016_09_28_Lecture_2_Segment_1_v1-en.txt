...
We ended lecture one looking at greedy solutions to the 0 to 1
knapsack problem.
We saw that they were easy to implement,
computationally efficient, but that they didn't always
necessarily give the right solution--
and promised that now we would look
at finding optimal solutions.
So the obvious one-- we already saw this in some form--
was a brute force algorithm.
We ennumerate all possible combinations of items.
Then we remove all the combinations whose total weight
exceeds the allowed weight.
And finally, from the remaining combinations,
we choose any one whose value is the largest.
Now, these are great words.
But they don't translate immediately to code.
So that's what I want to do now.
And we're going to implement this using
what's called a search tree.
So let's look at how that works.
The tree is built top down starting with the root.
The first element is selected from the still-to-be considered
items.
If there is room for that item in the knapsack,
a node is constructed that reflects a consequence
of choosing to take that item.
By convention, we draw that as a left child.
The right child shows the consequences
of not taking that item.
We then apply this process recursively
to non-leaf children because each edge of this tree
represents a decision to take or to not take an item.
Such trees are called decision trees, or, more often,
search trees.
Finally, when we're done, we've explored all possibilities,
and we choose a node with the highest value.
Before we look at code, let's look at an example pictorially.

So here we have a situation.
We you have a very small menu-- beer, pizza, and burger.
And we start with an empty knapsack.
So that's the top, or root, of our tree.
We then say, what happens if we take the beer?
Well, now we have a knapsack with beer,
and we still have pizza and hamburger to think about.
We can now say, well, let's take the pizza, take the hamburger.
So we've explored one possibility systematically,
the possibility of taking everything.
Of course, we're not done with the tree.
So what we do now is, we backtrack.
We move from this leaf node back up to its parent
and ask the question have we considered all possibilities?
The answer is no, since we haven't
considered the possibility of not taking the burger.
So now, we consider that possibility.
What we're doing here is a left first, depth first enumeration.
We always choose the left, decision first.
That's the decision to take.
And we go all the way to the bottom of the tree.
Then we start backing up and consider the next decision.
So here, the decision is not to take the burger.
And we have that.
Nothing to do here.
We now back up.
Well, we decide we've explored all possibilities here.
So we back up again to here and explore
what happens if we don't take the pizza.
We now have a knapsack with just beer.
We now say, let's take the burger,
let's not take the burger.
We back up all the way to the root this time, since we've now
explored everything, and say, well,
suppose we don't take the beer.
We get here, and then we just do the same thing over.
And when we're done, we've explored all possibilities,
we can then look at what the value of each is,
and what the calories.
If there are too many calories, for example,
766 is bigger than 750, then that node is not eligible,
and we just go through, and we choose the eligible node
that has the highest value.
Guaranteed to find an optimal solution because we've looked
at all possible solutions.
Now you might wonder why the tree has the root at the top
and the leaves at the bottom.

I have no idea why computer scientists
draw their trees that way.
I can only guess it's because we spend
too much time at our computers and not enough time communing
with nature.
Now let's think about how much computation is required
to build a search tree.
The amount of computation will be
proportional to the number of nodes in the tree.
To see how many nodes there will be,
we look at the number of levels in the tree
and the number of nodes per level.
Now the number of levels will be equal to the number of items
we have to choose from because each level represents
a decision to take or not take a specific item.
The number of nodes at each level, at level i,
to 2 to the i.
So if there are n items, the number of nodes
is the sum from 0 to n of 2 to the i, which
is order 2 to the i plus 1.
So what we see is, it is, as we knew it had to be, exponential.

Now there's an obvious optimisation.
We don't need to explore the parts of the tree that
violate the constraint, for example, too many calories.
We could just not generate those nodes,
but that doesn't change the complexity algorithm.
It's still the same.
Well, does the fact that it's exponential
mean that brute force is never useful?
Well, let's give it a try and see.
So let's start by looking at the header of our implementation
for the decision tree.
It's going to take two arguments.
The items to be considered and the available weight,
the constraint, and then it will return
a tuple containing the items we decided to take,
and their total value.
We're going to be calling this recursively,
and so, at each call, these things will change.
So that's why I say the amount of space
is still available because in the recursive calls
it will not, of course, be the same as was available
initially.
And for similarly, we'll be looking
at the not yet considered items, which will change
with each recursive call.
Here is the body.
Nothing very complicated here.
So if there is nothing left to consider,
or the available weight is 0, then we'll
return the tuple 0 and empty.
Otherwise, we'll look at the first item that's still in
"to consider."
If its weight is more than it is available,
then we know we can't take it.
So we'll return max val of "to consider" without that item.
We're slicing it here.
And avail, unchanged.

Otherwise, we'll go to the next item is "to consider" of 0.

Now we know we can take it, and then we're
going to get with val, with "to take"
is equal to the maximum value of, again, the list
without that first item.
So that doesn't change.
But available has to change because now we
have to reduce it by the units of that item of
to consider subzero.

And then we can increase with val by the value of that item.
All right, so far so good.
The next line is without val, the value
if we don't take the item, and without to take.
Again, we'll look at max val of to consider
minus the first item and available
because we haven't taken it.
So it doesn't change what's available.
It doesn't change the value.
We then simply test whether the left branch or the right branch
was better by saying if with val is more than without val,
this is the result. Otherwise, that's the result,
and we return it.
What I want you to notice is that we're not actually
building the search tree.
The local variable result records the best solution
found so far.

This will work.
I hope you can see that it's obviously correct solution.
Let's see what happens if we run it.

So we're going to run it here with the same menu we
looked at before.
We'll also test greedies just to show
that we're getting something different
from the greedy algorithms.
And if we run it, here's what we get.

Notice that this optimal solution, which
is truly optimal, is actually better than any
of the greedy solutions.
We get 353 units of value out of our menu.
Of course, we might not like the idea
that the solution contains three drinks and only one solid food.
How could we have avoided that?
Not by changing the algorithm, not by not doing a search tree,
but perhaps by having a richer set of constraints
on the optimization problem, which
would tell us which solutions are truly admissible.
Here's the code for max val.
I'll apologize for not including the comments,
but I wanted to squeeze it all onto one slide,
and it wouldn't work if I have the comments.
But I'll talk you through them anyway.
So the first line says, if "to consider" is empty,
or there is nothing available, well,
then the result we're going to return
is no value and no items.
However, if we're not in that case,
the first thing we're going to do
is check whether the first item in to considered, item 0,
will fit in the knapsack.
Otherwise, if the first item would not fit in the knapsack,
I can safely assume I'm not going to take it,
and my result will be whatever the maximum value would be of
"to consider" without the first item
and what was previously available because that
hasn't changed.
And so I use slicing to get rid of the first item.
Suppose it would fit in a knapsack.
Then I have to consider two branches, the left branch,
where I take it, and the right branch, where I don't.
So let's squirrel the value of "to consider" 0
away in next item.
And first, we'll look at the left branch.
So that's where I take it.
So with val, the value when I take it, and with to take,
is equal to the max val of 2 consider without that item.
And I have to change availability
to be availability minus the weight of the item I've just
considered taking.
And I have to also change with val
to indicate that I get the value associated with that item.

I then look at the right branch, where I don't take it,
and that will be, as up here, max val
of to consider without the first item and avail.
And then, finally, I choose the better
of the left and the right branch here and return that result.
A straightforward recursive implementation
of the left first depth first search
that we looked at before, with the slight optimization of not
exploring the nodes that wouldn't fit in.
OK, notice that we're not actually
building the search tree.
Instead, we're using the local variable result
to record the best solution thus far.

All right, let's try it on our example from lecture 1.
Here is the menu.
Again, I'll assume our calorie budget is 750.
And we'll try and really choose an optimal solution this time.
So what we see over here in the code is,
I've built the menu as before.
I'm going to run test greedies as before.
And then we'll test max value and see
if we get a different answer.

And sure enough, we do.
You'll notice that max val finds a solution that actually
yields a value of 353, as opposed
to the previous best of 318.
Now the solution we might not like-- cola, pizza, beer,
and wine-- maybe we don't like the fact that there
are three drinks and only one piece of food.
How could we have avoided this?
Pretty easily.
We could have started by defining the problem
differently and layered on a constraint
about the relative balance, say, of food and drink.
OK the search tree worked great.
It gave us a better answer than we
got from the greedy algorithms.
As you saw, it finished very quickly.
However, we should keep in mind that 2 to the eighth
is not a large number.
And we should look at what happens
when we have a more extensive menu
to choose from and see if the optimal algorithm still
is acceptably efficient.
And we'll do that in the next segment.
