- So we are back on the shell.
Here is my Python 4 Data Science, my first directory,
working directory.
So we have the P-W-D here, we can see where we are.
And let's do an L-S.
What was in this directory?
Right, we had the fruits.txt, we had the shakespeare.txt
we explored with them.
Let's keep exploring a little bit more,
simply with head and tail commands
and some pipes and filters.
I can first start by looking at
the first five lines of fruits.txt.
If you remember, fruits.txt,
it has some fruit names in it, right?
I'll get the first five using head minus five
fruits.txt and I see that I got the top five lines.
Then maybe it's good to see the first five lines
of all fruit files that I have.
In this case remember that asterisks,
our wild-card operator, we'll use that one.
So if I simply say head minus five
you see all those fruits files there, right, Fruits star
I'll see here, fruits sorted with the first five lines,
apples are nicely sorted.
Fruits unique, we don't have anything
that has double names here
because they're all unique names,
and now we have the fruits.txt,
so we did this in our last session.
I can also pipe the output to a cat command,
but it will show me the input it receives anyway.
Just for completeness let's clear our screen,
and say head minus five fruits star that's the all tree,
and then we do pipe that into a cat
so we see the same output.
Let's look at the last three lines
in all the fruits files, using the same logic.
Stop for a second, think how you would use
the tail command to get the last three lines.
We will just switch the head command
with the tail command here.
So we can say, tail minus three fruits star
and then I'll just cat that into
pipe that into a cat.
Here we see the last three lines of all three files.
Let's clear our screen, and imagine we want to now see
the first and last two lines in the file,
let's say fruits-sorted.txt, how would we do that?
Remember that parenthesis and we use that
as a composite to commands together
and stitch them with a semicolon
in one of our earlier videos.
We'll use the same logic,
and we can say head minus two tail minus two
and we'll redirect input to come from
that file we wanted, fruits-sorted.txt.
Here we see the first two lines and the last two lines
of that fruits-sorted.
We can also use another Unix command,
and this is a new one: the paste command
to merge all fruit files into one file.
So we'll use the wild card with fruits star,
but we'll say paste fruits star
and then I'll name a file called all-fruits.txt.
It's going to put all the
contents of the fruits file
together into a file called all-fruits.txt.
If we cat into this file,
we'll see that paste put the output
side by side from each line.
So this paste command in this way
can be pretty powerful when creating tabular data
from multiple files, and it's a pretty useful command
for data science for that purpose.
So now we know how we can do simple file manipulation,
using head and tail commands.
Let's switch to our first question.
Our first question was,
what are the top 15 words used in Shakespeare's works?
It's this file, let's say cat shakespeare.txt
word count shakespeare.txt.
We want to quickly know about this file, right?
We see that there's 124 thousand lines,
and many words and characters in this file,
so it's a longish file.
And there are also, when I look at this output,
there are a bunch of blank lines,
so that definitely adding to our line count,
but it's complete.
If you wanted to see the top of it,
which is generally useful,
I would pipe this into a more command,
and I would see the file.
Just explore with the file from the top to bottom
if I want, I can get out using Q.
Now, let's apply our sed regular expression
to turn each word into a line.
So we see that every line here has a bunch of words,
separated by spaces, so we need to find that sed expression,
like we had in our introductory video
that takes those spaces
and replaces them with new lines.
So we'll start with an S slash in our regular expression,
and with a slash G for globally doing this through the file.
In my Mac, the sed expression is kind of complicated,
so I'll just switch back, not to just type it wrong.
This is the sed expression for Mac.
So now what I'm doing here is I have sed minus E,
and started with S slash, and ended the slash G
and in between I have two slash characters,
the first part of the slash is just a space,
because remember I'm trying to replace the spaces
the characters in between the second and third slash
in my regular expression are really to get around
some special characters in Mac in another Unix shell
it could have just sed backslash N,
and it should have worked.
So let's try this.
Remember, the top of my screen now shows
the contents of shakespeare.txt.
I'm piping that file as an input to sed,
S-E-D, our stream editor, to replace those characters.
Just think for a second what you will expect to see.
Exactly, we will see.
Hopefully you were able to guess it right.
We see each word in our input file on a separate line.
So we now have all the words on separate lines,
we want to pipe it into a sort to sort those words.
So I have pipe sort, let's see the output of sort.
It's gonna take a little bit more time
because remember we are going through each word twice now.
So we'll have to wait for a second,
and depending on your computer
this might take a little while.
But now here what we are seeing is
we see all the words nicely sorted.
We sorted the words, but if I go back, actually,
to the beginning of this I would see
all those blank ones, also.
We want to remove all those blank lines, now.
So to this pipe I'm adding now,
I'm piping the output of sort, to another S-E-D command,
and it's going to get rid of those blank lines,
and after those we've now prepared our output stream
from the pipe for the unique command.
And we got rid of the blanks, and we sorted it,
so let's just also run the unique command,
with the minus C option, and see what the output is.
The bigger the file, the longer it takes,
which is one reason for us to learn Python.
Here we are seeing all words,
now we got our output, and a count of those words.
Remember those words we have sorted.
Now we are seeing each word, or a set of characters.
Some of them, like "you" has multiple characters
associated next to each other, they are counted separately.
We could have processed our input further
to actually make sure the "you" is "you".
"You.", "you;", "you:", they are all counted one
but we didn't go that far,
so we count all of those separately.
But what we are seeing in the uniques output now
there's the count for each word,
how many times that each word occurred in our input stream.
But it's not sorted, right,
there's all the words I sorted, but numbers aren't,
so we want now sort that numerically.
So if I say sort N-R, I'll actually sort that same output
to list the count
in a sorted way for each word.
So here we see now the last ones in an ascending way.
Maybe we should sort this into
pipe this into more
so we could see the output stream a little better.
Because we want to see the top five,
we'll get that top five next.
See that the sort is being done
here "the", the word "the", occurred
22 thousand something times, and the next one is
19 thousand and it goes down from there.
Let's remember that last couple in the end
was used one time only.
I'm just gonna go quickly.
It goes on pretty dramatically after a while.
But remember, our question was take the top 15 count.
So instead of more, I should just use the head
and head 15, so we want that top 15 counts from this output.
And once we get this output we'll redirect the output
into a file that we call count versus where it's
and later on we'll use, actually, that file to redirect
those top 15 into a plot using gnuplot.
We got the output of our whole pipe here,
as you see, we have that top 15 starting with
"the", "I", "and", and it goes down to "with" here.
So I'm going to quickly
do the same thing but I'll pipe it into count versus words,
just like we had in our example on our slides.
So while it's processing,
and writing all the output into that file,
I started saying a while back
this is why we also want to learn Python,
because the longer, or the bigger the data size gets,
the slower doing it just on the Unix shell will be.
Or sometimes even the paralyzing use scalable execution.
Python really gives us those libraries
to do those things really more efficiently.
Data manipulation, visualization, analysis and
in general every step of our data science process.
Now we have it, if we just have,
say cat count versus words,
we'll see those same 15 lines
nicely sitting in our count versus words file.
Let's shelf that for a while and clear our screen,
and focus on our second question from our slides.
The question there was,
"which users run the most processes on my Unix system?"
we haven't gone through it on detail on our slides
and I said in the live demo we'll go through this.
Let's start thinking, I'm talking about
the processes on my Unix system.
And I need to know about, first of all,
what processes are running on my Unix system,
we'll use the P-S command for that,
with some special options.
And as we are using the P-S command I'll explain you
which column is the user's, what's the process,
and things like that.
So as I mentioned, I'll first have to list all processes
by all users and terminals, and I said
I'll use some special options toward the P-S command.
If you just say P-S minus A-E-F,
I'll have this long output stream.
Let's actually pipe that into more,
so we can see the top of it.
Here we see that the first line of the output is
the column names for this.
And the first command in there,
and the first column in there, excuse me, is the UID.
It's for unique user identifiers.
I see, for example, zero for the system, or the kernel,
and 501 if I go more on this,
I'll see 501 running some UID, that first line here.
501, for example, for the identifier
of the first user account created in my Mac OSX System.
That happens to be me.
To list all the users,
how do I know which ID belongs to which user, right?
We can use another Unix command,
and we can say, list all in the users
directory, with a unique identifier.
So here we see those unique identifiers for different users.
Remember, I said zero was for the kernel, let's find zero.
That's the first one is the root, here.
And 501 was for all altintas, that's me.
And 201 is the guest, and it's
there are some special users that are
running things in my system, actually,
for me in the background.
Okay, so let's go back to our P-S A-E-F more.
We wanna cut those user identifiers from each process,
so we will use the cat command for that.
Because our question said
which users are running the most commands,
so we'll first find those user identifiers and output those,
and then we'll sort each line, and build a unique
just like we did before.
So let's add to our pipe instead of more,
I'll say cut minus C three minus five.
This says cut the section
from character three to character five,
which is roughly our user identifier.
If I go through this output in a text file,
that's what I would see, then let's pipe it into more.
So what we are seeing here is only the user identifiers.
From all those processes that are running,
I cut those user identifiers,
and we see 501 and zero happen a number of times.
So we want to cut how many unique user identifiers
there are, and how many times they occur in my system.
We use this exact same logic
for our Shakespeare example before.
What we've done is we sorted each line,
and found out how many processes each user ID is running,
using the unique command,
so if I just say this, I'll see, for example,
user ID zero is running 115 commands,
and user ID 501 is running 220, UID,
since we didn't do a lot of text cleaning,
that first line, UID line, is still in my output.
That makes sense, so we are sort of going to
ignore that for this example.
So now that we have the unique number,
let's sort them numerically, because which users are running
the most processes was the question.
So we've done the same exact
numerical sort a few minutes ago,
so we'll use the same one.
So we now know 501, which is my account,
is running the most amount of processes.
Now that we've sorted each user and the number of processes,
we'll finally use head to get the top three users,
in terms of how many processes they are running.
We'll just pipe the whole output into head minus three,
it's gonna give us the top three lines,
because our original question was that.
A side question we can answer
is how many processes I am running.
So I don't have to sort the whole thing.
I know my user ID is altintas,
and the number, unique identifier for that user ID is 501.
We just went through that.
Instead of counting all the output of sort with unique,
we can go back to this sort step and
we can use the grab command,
and then after finding all the lines,
using grab, that has the UID 501 in it,
we can use the word count with the minus L option,
and we can find that same number
for the processes I'm running.
So I'm gonna change this to grab 501,
so it's gonna look for that 501 pattern
in the input stream for grab,
and then we'll pipe that into W-C minus L,
it's gonna give me that first number here, which is 221.
There we go.
I'm running 221 processes right now on this Unix system.
We've seen something different here.
We've seen in this output
we got me running 221 processes,
and in this one that we did the head command,
at that moment I was running 222 processes.
So a process was probably active and it finished,
so my process count went down to 221.
So you see that Unix is an active system,
a lot of things are being taken care of for you
in the background, so we see an example of that here.
So there's still another side note here,
because we used the process command P-S,
and let's check the output of it one more time.
Let's just do this, P-S minus A-E-F,
I'll first clear my screen for this one, for clarity,
and I'll say P-S minus A-E-F,
and let's pipe it into more so we can see the top of that.
Okay, there we are.
So we see here things like PID, PPID.
Let's spend just a few seconds on what these mean.
In every Unix-based system, there's a process with PID one,
and you see that here, route runs that PID process one,
and it becomes a parent process, PPID,
for many other processes.
This process is called, actually, the grandparent
of all the processes in the Unix system,
and depending on your Unix system
it's either launch H-D or in it its name changes,
but it is really the first process,
the grandparent of all the processes.
And the kernel, the root itself, has the PID of zero.
In addition to a unique PID, each processes also have
this PPID, parent process ID.
That tells which process started it.
The PPID is the PID of the process's parent.
And the parent processes
start new processes as sub processes.
So after this quick process overview,
let's go back to our first question again,
and try to plot the results of the pipe.
Remember, lets' clear our screen,
remember we used count verses words,
the file, to save those results,
the counts of each word, top 15 words.
So this was our pile, and we got the outputs.
Now we will use gnuplot
to actually plot these numbers
on something like a bar chart.
So when I enter gnuplot I have installed it on my Mac.
I see my gnuplot interface,
so I'm gonna save, actually,
the plot into a .png file, so I'll just say
set term to P-N-G, so save the output,
the image that comes out of the graph into a file
with a .png extension
and now I'll say output file will be
something like word-counts.png.
And I'm just coming up with any file name, here.
And I could do a number of things
to set the parameters of let's say,
the width of the bars in my chart.
I can set style to a histogram style.
And I can choose to do a solid fill,
so I can actually keep improving my style here.
Fill solid, 1.0, with some border extensions.
So don't worry about these lines yet,
because we are not using gnuplot.
I'm just showing this as an example.
But hopefully if you're interested
you can go explore further.
So now what we are going to do is start plotting
that counts versus words file that we created.
So we'll say plot and
getting some inputs here.
We are going to use our counts versus words,
where it is our input file, and using some labels.
So now actually when I go back to this directory,
let's exit our gnuplot.
Our file name, if you remember, was word-counts.png.
I'll see word-counts.png file here.
I need to go back to our directory,
Python four data science, my first directory,
and here we have word-counts.png, you see?
And here we have the "the", "I",
and all the rest of the words, remember,
"the" was 22-thousand-something times,
and it went down to 19 thousand and onwards.
So we do a quick data plot to see how its progressing
in terms of word counts for the first 15.
Here we see in that sense that bar chart
that we just created, very simple,
and definitely needs some improvements, this example,
but we see how we can use Unix command
and how powerful and quick it can be
once we master how to use the pipes and filters
with some commands and data and text manipulation.
This is the end of our Unix overview.
Next, we will review how we can interact
with these commands from Jupyter Notebooks
after a quick review of the notebooks
and their ability to ingest and interact
with various programming languages,
one of which happens to be Unix.